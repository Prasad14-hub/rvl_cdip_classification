{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Experiment with 5,000 Samples\n",
        "\n",
        "- **Purpose:** Test ViT-Base on a small subset to establish a baseline for document classification.  \n",
        "- **Details:** Random sampling led to uneven class distribution, resulting in lower accuracy (**59.15%**).  \n",
        "- **Outcome:** Identified need for balanced sampling, implemented in later experiments.  \n"
      ],
      "metadata": {
        "id": "JSszty-qVdSE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjNspX67F0QE",
        "outputId": "07d72499-5e2b-42d7-9c86-9e4ff1624902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing device: cuda\n",
            "GPU name: Tesla T4\n",
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       1.7Gi       256Mi       1.0Mi        10Gi        10Gi\n",
            "Swap:             0B          0B          0B\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   40G   74G  35% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G     0  5.7G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  820M  59% /usr/sbin/docker-init\n",
            "/dev/sda1        92G   69G   23G  76% /opt/bin/.nvidia\n",
            "tmpfs           6.4G  208K  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ],
      "source": [
        "# Installing required libraries\n",
        "!pip install -q transformers datasets torch torchvision accelerate\n",
        "\n",
        "import torch\n",
        "from transformers import ViTImageProcessor, ViTForImageClassification, TrainingArguments, Trainer\n",
        "from datasets import load_dataset, IterableDataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Check GPU and resources\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "!free -h  # Check RAM\n",
        "!df -h   # Check disk space"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load Dataset with Streaming\n",
        "dataset = load_dataset(\"aharley/rvl_cdip\", streaming=True)\n",
        "\n",
        "label_map = {\n",
        "    0: \"letter\", 1: \"form\", 2: \"email\", 3: \"handwritten\", 4: \"advertisement\",\n",
        "    5: \"scientific report\", 6: \"scientific publication\", 7: \"specification\",\n",
        "    8: \"file folder\", 9: \"news article\", 10: \"budget\", 11: \"invoice\",\n",
        "    12: \"presentation\", 13: \"questionnaire\", 14: \"resume\", 15: \"memo\"\n",
        "}\n",
        "num_labels = len(label_map)\n",
        "\n",
        "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "class StreamingDataset(IterableDataset):\n",
        "    def __init__(self, dataset_split, max_samples):\n",
        "        self.dataset = dataset_split\n",
        "        self.max_samples = max_samples\n",
        "        self._epoch = 0  # Initialize epoch tracking\n",
        "\n",
        "    def __iter__(self):\n",
        "        count = 0\n",
        "        for example in self.dataset:\n",
        "            if count >= self.max_samples:\n",
        "                break\n",
        "            image = example[\"image\"].convert(\"RGB\")\n",
        "            inputs = processor(images=image, return_tensors=\"pt\")\n",
        "            yield {\n",
        "                \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n",
        "                \"labels\": example[\"label\"]\n",
        "            }\n",
        "            count += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.max_samples\n",
        "\n",
        "    def set_epoch(self, epoch: int):\n",
        "        self._epoch = epoch  # Update epoch value as required by Trainer\n",
        "\n",
        "train_size = 5000\n",
        "val_size = 2000\n",
        "test_size = 2000\n",
        "\n",
        "train_dataset = StreamingDataset(dataset[\"train\"], train_size)\n",
        "val_dataset = StreamingDataset(dataset[\"validation\"], val_size)\n",
        "test_dataset = StreamingDataset(dataset[\"test\"], test_size)\n",
        "\n",
        "print(f\"Training size: {train_size}, Validation size: {val_size}, Test size: {test_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkwA79b2GCIk",
        "outputId": "c976be00-061e-4dc1-e88f-7987f3000c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 5000, Validation size: 2000, Test size: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load Pre-trained ViT Model\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224-in21k\",\n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "model.to(device)\n",
        "print(f\"GPU memory allocated: {torch.cuda.memory_allocated(device) / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiDQ7hUKGCLT",
        "outputId": "27d1b95b-c350-450e-d9f1-0ec2a96d5279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory allocated: 654.69 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define Metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ],
      "metadata": {
        "id": "j24rDYDyGCOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Set Up Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./rvl_cdip_vit\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=8,\n",
        ")"
      ],
      "metadata": {
        "id": "Ichr0WoBG5Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train the Model\n",
        "print(\"Checking GPU availability before training...\")\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "print(f\"Current device: {torch.cuda.current_device()}\")\n",
        "print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "print(f\"GPU memory allocated post-training: {torch.cuda.memory_allocated(device) / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W103A-ufG6ZA",
        "outputId": "0ef0104c-7c66-4c09-cba1-271b47ff6ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking GPU availability before training...\n",
            "GPU available: True\n",
            "Current device: 0\n",
            "Device name: Tesla T4\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [468/468 16:31, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.171100</td>\n",
              "      <td>2.079495</td>\n",
              "      <td>0.519500</td>\n",
              "      <td>0.503776</td>\n",
              "      <td>0.519500</td>\n",
              "      <td>0.472049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.644700</td>\n",
              "      <td>1.750604</td>\n",
              "      <td>0.591500</td>\n",
              "      <td>0.611070</td>\n",
              "      <td>0.591500</td>\n",
              "      <td>0.559292</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory allocated post-training: 1325.74 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate on Test Set\n",
        "test_dataset = StreamingDataset(dataset[\"test\"], test_size)\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"Test Results:\", test_results)\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "labels = predictions.label_ids\n",
        "financial_classes = [1, 10, 11, 15]\n",
        "for cls in financial_classes:\n",
        "    mask = labels == cls\n",
        "    cls_preds = preds[mask]\n",
        "    cls_labels = labels[mask]\n",
        "    acc = accuracy_score(cls_labels, cls_preds) if len(cls_labels) > 0 else 0\n",
        "    print(f\"Accuracy for {label_map[cls]} (label {cls}): {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "T_e59QlNMGWZ",
        "outputId": "17064c56-64e9-4e1f-e165-e6159a489138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: {'eval_loss': 1.7476862668991089, 'eval_accuracy': 0.5915, 'eval_precision': 0.5596926554267293, 'eval_recall': 0.5915, 'eval_f1': 0.5564453816774622, 'eval_runtime': 158.5213, 'eval_samples_per_second': 12.617, 'eval_steps_per_second': 3.154, 'epoch': 2.9856}\n",
            "Accuracy for form (label 1): 0.2126\n",
            "Accuracy for budget (label 10): 0.4275\n",
            "Accuracy for invoice (label 11): 0.6975\n",
            "Accuracy for memo (label 15): 0.1788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Save the Model\n",
        "model.save_pretrained(\"./rvl_cdip_vit_model\")\n",
        "processor.save_pretrained(\"./rvl_cdip_vit_model\")\n",
        "!du -sh ./rvl_cdip_vit_model\n",
        "!df -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU6TQQjxG6cc",
        "outputId": "780b5c27-0c83-4e6c-b247-fa5f1a39725b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "328M\t./rvl_cdip_vit_model\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   43G   70G  38% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G   24K  5.7G   1% /dev/shm\n",
            "/dev/root       2.0G  1.2G  820M  59% /usr/sbin/docker-init\n",
            "/dev/sda1        92G   71G   22G  77% /opt/bin/.nvidia\n",
            "tmpfs           6.4G  308K  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    }
  ]
}