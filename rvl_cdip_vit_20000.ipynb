{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Full ViT Experiment with 20,000 Samples\n",
        "- **Purpose**: Maximize ViT-Base performance within Colab constraints using a larger, balanced dataset.\n",
        "- **Details**: Trained for **6** epochs with early stopping (patience=2), achieving **78.85%** accuracy.\n",
        "- **Outcome**: Strong results for financial classes (e.g., Invoice: **72.8%**), saved model to `models/rvl_cdip_vit_model/`."
      ],
      "metadata": {
        "id": "jZtKsH4rb0VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking system resources\n",
        "import torch\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "# CPU and RAM info\n",
        "print(f\"Total RAM: {psutil.virtual_memory().total / (1024**3):.2f} GB\")\n",
        "print(f\"Available RAM: {psutil.virtual_memory().available / (1024**3):.2f} GB\")\n",
        "print(f\"Used RAM: {psutil.virtual_memory().used / (1024**3):.2f} GB\")\n",
        "print(f\"CPU Count: {os.cpu_count()}\")\n",
        "\n",
        "# GPU info\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Total GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
        "    print(f\"Allocated GPU Memory: {torch.cuda.memory_allocated(0) / (1024**2):.2f} MB\")\n",
        "    print(f\"Free GPU Memory: {torch.cuda.memory_reserved(0) / (1024**2):.2f} MB\")\n",
        "else:\n",
        "    print(\"No GPU available yet. Try again later or check runtime settings.\")\n",
        "\n",
        "# Disk info\n",
        "!df -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF8C_ZC3OGKl",
        "outputId": "0b382335-b180-4416-c58c-9cd94772b353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total RAM: 12.67 GB\n",
            "Available RAM: 11.20 GB\n",
            "Used RAM: 1.17 GB\n",
            "CPU Count: 2\n",
            "GPU Available: True\n",
            "GPU Name: Tesla T4\n",
            "Total GPU Memory: 14.74 GB\n",
            "Allocated GPU Memory: 0.00 MB\n",
            "Free GPU Memory: 0.00 MB\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   40G   74G  36% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G     0  5.7G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  820M  59% /usr/sbin/docker-init\n",
            "/dev/sda1        92G   72G   21G  79% /opt/bin/.nvidia\n",
            "tmpfs           6.4G  904K  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxYKXiZ4ICuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd80611-0218-45a3-f7b6-dbefd9dd293d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU name: Tesla T4\n",
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       1.9Gi       846Mi       2.0Mi         9Gi        10Gi\n",
            "Swap:             0B          0B          0B\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   40G   74G  36% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G     0  5.7G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  820M  59% /usr/sbin/docker-init\n",
            "/dev/sda1        92G   72G   21G  79% /opt/bin/.nvidia\n",
            "tmpfs           6.4G  916K  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Installing required libraries & Setting up the Environment\n",
        "!pip install -q transformers datasets torch torchvision accelerate\n",
        "\n",
        "import torch\n",
        "from transformers import ViTImageProcessor, ViTForImageClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "from datasets import load_dataset, IterableDataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from collections import defaultdict\n",
        "from torchvision import transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "!free -h\n",
        "!df -h"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Loading Dataset with Balanced Streaming and Augmentation\n",
        "dataset = load_dataset(\"aharley/rvl_cdip\", streaming=True)\n",
        "label_map = {0: \"letter\", 1: \"form\", 2: \"email\", 3: \"handwritten\", 4: \"advertisement\",\n",
        "             5: \"scientific report\", 6: \"scientific publication\", 7: \"specification\",\n",
        "             8: \"file folder\", 9: \"news article\", 10: \"budget\", 11: \"invoice\",\n",
        "             12: \"presentation\", 13: \"questionnaire\", 14: \"resume\", 15: \"memo\"}\n",
        "num_labels = len(label_map)\n",
        "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "class BalancedStreamingDataset(IterableDataset):\n",
        "    def __init__(self, dataset_split, total_samples, num_classes=16):\n",
        "        self.dataset = dataset_split\n",
        "        self.total_samples = total_samples\n",
        "        self.target_per_class = total_samples // num_classes  # ~1250 for 20,000\n",
        "        self.num_classes = num_classes\n",
        "        self._epoch = 0\n",
        "        self.augment = transforms.Compose([\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        ])\n",
        "\n",
        "    def __iter__(self):\n",
        "        class_counts = defaultdict(int)\n",
        "        samples_yielded = 0\n",
        "        for example in self.dataset:\n",
        "            label = example[\"label\"]\n",
        "            if class_counts[label] < self.target_per_class:\n",
        "                class_counts[label] += 1\n",
        "                image = example[\"image\"].convert(\"RGB\")\n",
        "                image = self.augment(image)\n",
        "                inputs = processor(images=image, return_tensors=\"pt\")\n",
        "                yield {\n",
        "                    \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n",
        "                    \"labels\": label\n",
        "                }\n",
        "                samples_yielded += 1\n",
        "                if samples_yielded >= self.total_samples:\n",
        "                    break\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_samples\n",
        "\n",
        "    def set_epoch(self, epoch: int):\n",
        "        self._epoch = epoch\n",
        "\n",
        "train_size = 20000  # 20,000 samples\n",
        "val_size = 2000\n",
        "test_size = 2000\n",
        "train_dataset = BalancedStreamingDataset(dataset[\"train\"], train_size)\n",
        "val_dataset = BalancedStreamingDataset(dataset[\"validation\"], val_size)\n",
        "test_dataset = BalancedStreamingDataset(dataset[\"test\"], test_size)\n",
        "print(f\"Training size: {train_size}, Validation size: {val_size}, Test size: {test_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4oOBCRWIWwP",
        "outputId": "af8ad3b7-28e9-4417-bcf4-c2ced6c70d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 20000, Validation size: 2000, Test size: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load Pre-trained ViT Model\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224-in21k\",\n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "model.to(device)\n",
        "print(f\"GPU memory allocated: {torch.cuda.memory_allocated(device) / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_vICbc2IWy_",
        "outputId": "37b7ebbe-d198-44b8-eb53-d11edfbee2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory allocated: 327.34 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define Metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ],
      "metadata": {
        "id": "B963qEnqIW1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Set Up Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./rvl_cdip_vit\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=8,  # Effective batch size 64\n",
        ")"
      ],
      "metadata": {
        "id": "6HJH840OIW4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train the Model with Early Stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "print(f\"GPU memory allocated post-training: {torch.cuda.memory_allocated(device) / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "xu3OidFRIW7c",
        "outputId": "ed5d2a47-d0e0-4c9a-e28f-d191fc126f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgavhaneprasad14092001\u001b[0m (\u001b[33mgavhaneprasad14092001-indian-school-of-mines\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250311_033439-tvxhimqh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gavhaneprasad14092001-indian-school-of-mines/huggingface/runs/tvxhimqh' target=\"_blank\">./rvl_cdip_vit</a></strong> to <a href='https://wandb.ai/gavhaneprasad14092001-indian-school-of-mines/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/gavhaneprasad14092001-indian-school-of-mines/huggingface' target=\"_blank\">https://wandb.ai/gavhaneprasad14092001-indian-school-of-mines/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/gavhaneprasad14092001-indian-school-of-mines/huggingface/runs/tvxhimqh' target=\"_blank\">https://wandb.ai/gavhaneprasad14092001-indian-school-of-mines/huggingface/runs/tvxhimqh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2184' max='2184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2184/2184 3:07:09, Epoch 6/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.475300</td>\n",
              "      <td>1.456652</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.654019</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>0.621840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.149600</td>\n",
              "      <td>1.163137</td>\n",
              "      <td>0.700500</td>\n",
              "      <td>0.713860</td>\n",
              "      <td>0.700500</td>\n",
              "      <td>0.699050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.990700</td>\n",
              "      <td>1.047009</td>\n",
              "      <td>0.720500</td>\n",
              "      <td>0.747403</td>\n",
              "      <td>0.720500</td>\n",
              "      <td>0.723401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.844200</td>\n",
              "      <td>0.920603</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.779007</td>\n",
              "      <td>0.757500</td>\n",
              "      <td>0.761513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.797900</td>\n",
              "      <td>0.855802</td>\n",
              "      <td>0.777000</td>\n",
              "      <td>0.791837</td>\n",
              "      <td>0.777000</td>\n",
              "      <td>0.780083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.679500</td>\n",
              "      <td>0.801961</td>\n",
              "      <td>0.789500</td>\n",
              "      <td>0.794783</td>\n",
              "      <td>0.789500</td>\n",
              "      <td>0.790739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 438958ce-54be-440f-8624-f48b32e70980)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 438958ce-54be-440f-8624-f48b32e70980)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 5e41a995-8973-47b7-a30a-bd4a885d803f)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 5e41a995-8973-47b7-a30a-bd4a885d803f)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f2f72e2c-1ffd-444c-a8e4-aaf3475cae61)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f2f72e2c-1ffd-444c-a8e4-aaf3475cae61)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: c43be7d9-1508-498c-b303-b32c0e91cfc8)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: c43be7d9-1508-498c-b303-b32c0e91cfc8)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: bc314ed0-36db-450b-a7e1-f2d3103e2b40)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: bc314ed0-36db-450b-a7e1-f2d3103e2b40)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e3b202bb-8b50-4cea-87cc-9cda562371bc)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e3b202bb-8b50-4cea-87cc-9cda562371bc)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 98d45f47-b3ab-4dfe-a45e-ff7a418f0017)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 98d45f47-b3ab-4dfe-a45e-ff7a418f0017)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory allocated post-training: 1000.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate on Test Set\n",
        "test_dataset = BalancedStreamingDataset(dataset[\"test\"], test_size)\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"Test Results:\", test_results)\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "labels = predictions.label_ids\n",
        "financial_classes = [1, 10, 11, 15]\n",
        "for cls in financial_classes:\n",
        "    mask = labels == cls\n",
        "    cls_preds = preds[mask]\n",
        "    cls_labels = labels[mask]\n",
        "    acc = accuracy_score(cls_labels, cls_preds) if len(cls_labels) > 0 else 0\n",
        "    print(f\"Accuracy for {label_map[cls]} (label {cls}): {acc:.4f}\")"
      ],
      "metadata": {
        "id": "xDnHUYpcJ8hp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "83dd3b8e-30fd-4bd0-c87e-249ed3ed39c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: {'eval_loss': 0.8201947212219238, 'eval_accuracy': 0.7885, 'eval_precision': 0.7906251192026067, 'eval_recall': 0.7885, 'eval_f1': 0.7887677059200332, 'eval_runtime': 451.1928, 'eval_samples_per_second': 4.433, 'eval_steps_per_second': 0.554, 'epoch': 6.9792}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 3846b642-2059-429b-9bd7-c40703be98a9)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 3846b642-2059-429b-9bd7-c40703be98a9)')' thrown while requesting GET https://huggingface.co/datasets/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for form (label 1): 0.6160\n",
            "Accuracy for budget (label 10): 0.6240\n",
            "Accuracy for invoice (label 11): 0.7280\n",
            "Accuracy for memo (label 15): 0.7120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Save the Model\n",
        "model.save_pretrained(\"./rvl_cdip_vit_model\")\n",
        "processor.save_pretrained(\"./rvl_cdip_vit_model\")\n",
        "!du -sh ./rvl_cdip_vit_model\n",
        "!df -h\n",
        "\n",
        "# Optional: Save to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -r ./rvl_cdip_vit_model /content/drive/MyDrive/rvl_cdip_vit_model"
      ],
      "metadata": {
        "id": "gEYOF6pSJ-o_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b47524a-4014-44bf-991b-066a7474482e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "328M\t./rvl_cdip_vit_model\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   47G   67G  42% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G   16K  5.7G   1% /dev/shm\n",
            "/dev/root       2.0G  1.2G  820M  59% /usr/sbin/docker-init\n",
            "/dev/sda1        92G   73G   20G  79% /opt/bin/.nvidia\n",
            "tmpfs           6.4G  1.1M  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    }
  ]
}